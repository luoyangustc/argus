# k8s平台使用

by屈啸

# k8s 使用场景

## 首先申请权限

目前k8s客户端（kubectl）部署在xs713上，需要有登录权限。具体操作如下：

* fork 项目 git@gitlab.qiniu.io:qbox/deploy.git
* 编辑 deploy/stepping\_stone/etc/qssh.ini ，添加登录xs713权限
* 发起 merge request，让瓜总\(@songyunfeng\) review
* 登录七牛jumpbox，qssh xs713

## 场景1：查看 pod list

```
qboxserver@xs713:~$ kubectl get pods --namespace=ava
NAME                                           READY     STATUS    RESTARTS   AGE
atflow-controller-2958627371-wrw0g             1/1       Running   0          22h
atnet-apiserver-1971848090-zlw37               4/4       Running   13         1d
ava-pod-terror                                 1/1       Running   1          2d
check-demo                                     1/1       Running   1          11d
mem-test                                       1/1       Running   1          16d
mxnetgpu-terror-classify-83t0s                 1/1       Running   0          3h
pvc-mounter                                    1/1       Running   1          11d

```

## 场景2：进入一个正在运行的 pod

```
kubectl exec -it <your-pod-name> -- env COLUMNS=$COLUMNS LINES=$LINES TERM=$TERM /bin/bash

```

## 场景3：创建 PVC

编写 PVC yaml

```
编写 PVC yaml

// cat ava-pvc-example.yml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: <your-pvc-name>
  namespace: ava
  annotations:
    volume.beta.kubernetes.io/storage-class: "rbd-ssd"
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: <storage-amount> // example: 128Gi
创建 PVC

kubectl create -f ./ava-pvc-example.yml
查看 PVC

kubectl get pvc --namespace=ava
NAME                                             STATUS    VOLUME                                     CAPACITY    ACCESSMODES   STORAGECLASS   AGE
ava-dataset-example                              Bound     pvc-95d06fc7-71dd-11e7-b0a6-6c92bf3068da   128Gi       RWO           ceph-rbd       1h
ava-dataset-terror                               Bound     pvc-71ed1851-7037-11e7-90a0-6c92bf306baa   512Gi       RWO           ceph-rbd       2d
ava-vgg-face-dataset                             Bound     pvc-b7bf4ce4-6b91-11e7-a61f-6c92bf306baa   512Gi       RWO           ceph-rbd       8d
recordio-config                                  Bound     pvc-ab996caf-49d2-11e7-9e26-6c92bf306baa   512Mi       RWO           ceph-rbd       51d

```

创建 PVC

```
kubectl create -f ./ava-pvc-example.yml
```

查看 PVC

```
kubectl get pvc --namespace=ava
NAME                                             STATUS    VOLUME                                     CAPACITY    ACCESSMODES   STORAGECLASS   AGE
ava-dataset-example                              Bound     pvc-95d06fc7-71dd-11e7-b0a6-6c92bf3068da   128Gi       RWO           ceph-rbd       1h
ava-dataset-terror                               Bound     pvc-71ed1851-7037-11e7-90a0-6c92bf306baa   512Gi       RWO           ceph-rbd       2d
ava-vgg-face-dataset                             Bound     pvc-b7bf4ce4-6b91-11e7-a61f-6c92bf306baa   512Gi       RWO           ceph-rbd       8d
recordio-config                                  Bound     pvc-ab996caf-49d2-11e7-9e26-6c92bf306baa   512Mi       RWO           ceph-rbd       51d

```

## 场景4：创建（临时测试） pod

编写pod资源描述文件

```
apiVersion: v1
kind: Pod
metadata:
  name: <your-pod-name>
spec:
  imagePullSecrets:
  - name: atlab-images
  containers:
  - name: <your-pod-name>
    imagePullPolicy: Always
    # 镜像
    image: reg.qiniu.com/ava-public/ava-mxnet-py27-gpu:latest
    # 环境变量
    env:
    - name: USE_DEVICE
      value: "GPU"
    command: ["sleep", "infinity"]
    resources:
      requests:
        alpha.kubernetes.io/nvidia-gpu: <gpu-num> // 申请的GPU核数
        cpu: 0.2  // 申请的CPU配额
        memory: 512Mi // 申请的内存
      limits:
        alpha.kubernetes.io/nvidia-gpu: <gpu-num>
        cpu: 0.8
        memory: 1Gi
    # pvc 挂载
    volumeMounts:
      - mountPath: /workspace/data
        name: dataset
        # readOnly: true 根据自身使用情况决定是否加上 readOnly
      # nvidia 的 lib，使用 GPU 时需要 mount 进来
      - mountPath: /usr/local/nvidia
        name: lib
        readOnly: true
  volumes:
    - name: dataset
      persistentVolumeClaim:
        claimName: <your-pvc-name>
        # readOnly: true 根据自身使用情况决定是否加上 readOnly
    - name: lib
      hostPath:
        path: /var/lib/nvidia-docker/volumes/nvidia_driver/latest
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          # GPU型号，如果对型号不敏感，可以删除这部分字段
          - key: nvidia-gpu-type
            operator: In
            values:
            # 如果多种型号都可以，可以依次写下可使用的型号
            - "Tesla-K80"
  # 当使用 GPU 机器时，需要加上以下 tolerations 字段
  tolerations:
    - key: dedicated
      operator: Equal
      value: gpu
      effect: NoSchedule

```

创建 Pod

```
kubectl --namespace=ava create -f ./ava-pod-example.yml

```

查看 Pod

```
kubectl --namespace=ava get pod <your_pod_name>
```

PS：

公共镜像列表：[https://cf.qiniu.io/pages/viewpage.action?pageId=62041225](https://cf.qiniu.io/pages/viewpage.action?pageId=62046247)

## 场景5：在 pod 中上传 / 下载数据

上传数据

一般在运行环境中下载了源数据的压缩包，解压之后需要将富媒体数据单独上传至Kodo，推荐使用 qshell qupload ，具体请参考：[https://developer.qiniu.com/kodo/tools/1302/qshell](https://cf.qiniu.io/pages/viewpage.action?pageId=62046247)

下载数据

使用 xsio.qiniu.io / nbio.qiniu.io 的域名代理，可以突破外网下载的带宽限制，例如：

```
// 例如，外链地址为：http://op40fbim7.bkt.clouddn.com/__face_datasets__/MS_Celeb_1M/AllData/MsCelebV1-ImageThumbnails.zip
// 则使用以下命令下载
curl http://xsio.qiniu.io/__face_datasets__/MS_Celeb_1M/AllData/MsCelebV1-ImageThumbnails.zip -H 'Host:op40fbim7.bkt.clouddn.com' -o MsCelebV1-ImageThumbnails.zip


```

## 场景6：清理环境

```
删除pvc

kubectl delete pvc <your-pvc-name>
删除pod

kubectl delete pod <your-pod-name>
```



